{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(\"ignore\")\nfrom sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, roc_auc_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom sklearn.naive_bayes import GaussianNB\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv('Default_Fin.csv')\ndf.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.rename(columns={'Defaulted?':'Defaulted'})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.info()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Null Values","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(12,8))\nsns.heatmap(data=df.isnull(),cmap='CMRmap')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"As we can see there are no null values ","metadata":{}},{"cell_type":"code","source":"df=df.drop('Index',axis=1)\ndf.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i in df.columns:\n    sns.distplot(df[i])\n    plt.show()\n    \n    ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1)As we can see bank balance and annual salary columns are almost has gaussian distribution \n\n2)Defaulted and Employed are binary columns ","metadata":{}},{"cell_type":"code","source":"df.describe()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"1) Approx 70.56 percent of the customers are employed \n\n2)The average bank balance of the customers are Rs.10024 with a minimum of 0 and maximum of Rs.31851\n\n3)The average annual salary of the customers are Rs.402203 with minimum $9263","metadata":{}},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.pairplot(df,hue='Defaulted')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"employed = df.query(\"Employed == 1\")\nunemployed = df.query(\"Employed == 0\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nfig=px.pie(df,values=employed['Defaulted'].value_counts(),names=['Defaulters','Non-Defaulters'],title='Distribution of defualters who are Employed')\nfig.update_traces(pull=[0.2,0,0.06,0.06,0.06,0.06])\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure()\nfig=px.pie(df,values=unemployed['Defaulted'].value_counts(),names=['Defaulters','Non-Defaulters'],title='Distribution of defaulters who are Unemployed')\nfig.update_traces(pull=[0.2,0,0.06,0.06,0.06,0.06])\nfig.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (20, 9))\nsns.set_style(\"dark\")\nsns.kdeplot(df[df['Defaulted']==1]['Bank Balance'])\nsns.kdeplot(df[df['Defaulted']==0]['Bank Balance'])\nplt.title('Default x Bank Balance',fontsize=25)\nplt.legend(labels=['Defaulted', 'Did Not Default'])\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"fig = plt.figure(figsize = (20, 9))\nsns.set_style(\"dark\")\nsns.kdeplot(df[df['Defaulted']==1]['Annual Salary'])\nsns.kdeplot(df[df['Defaulted']==0]['Annual Salary'])\nplt.title('Default x Annual Salaries')\nplt.legend(labels=['Defaulted', 'Did Not Default'])\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.heatmap(data.corr(),annot=True,cmap='Blues')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.countplot(data=df,x='Employed',hue='Defaulted',palette='nipy_spectral')\nplt.xlabel('Employed',fontsize=17)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df1=df\ndf1.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"bank_balance_bins = [0, 5000, 10000, 15000, 20000]  # Customize these bins \nannual_salary_bins = [0, 100000, 300000, 500000, 1000000] #Customizing the bins\ndf1['Bank Balance Bucket'] = pd.cut(df1['Bank Balance'], bins=bank_balance_bins, labels=['<5k', '5k-10k', '10k-15k', '15k-20k'])\ndf1['Annual Salary Bucket'] = pd.cut(df1['Annual Salary'], bins=annual_salary_bins, labels=['<100k', '100k-300k', '300k-500k', '500k-1M'])\n\n# Print the resulting DataFrame\ndf1.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.countplot(data=df1,x='Bank Balance Bucket',hue='Defaulted',palette='twilight_shifted_r')\nplt.xlabel('Bank Balance',fontsize=17)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10,8))\nsns.countplot(data=df1,x='Annual Salary Bucket',hue='Defaulted',palette='twilight_shifted_r')\nplt.xlabel('Bank Balance',fontsize=17)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=df.drop(['Bank Balance Bucket','Annual Salary Bucket'],axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Scaling the data","metadata":{}},{"cell_type":"code","source":"from sklearn.preprocessing import StandardScaler\n\nx=df.drop('Defaulted',axis=1)\ny=df['Defaulted']\nx=StandardScaler().fit_transform(x)\nx=pd.DataFrame(x,columns=df.iloc[:,:3].columns)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Splitting the data ","metadata":{}},{"cell_type":"code","source":"xtrain,xtest,ytrain,ytest=train_test_split(x,y,random_state=100,test_size=0.3)\nprint('Xtrain shape',xtrain.shape)\nprint('Xtest shape',xtest.shape)\nprint('Ytrain shape',ytrain.shape)\nprint('Ytest shape',ytest.shape)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Model Building","metadata":{}},{"cell_type":"code","source":"#Train different models\nmodels = {\n    'Logistic Regression': LogisticRegression(),\n    'Decision Tree': DecisionTreeClassifier(),\n    'Random Forest': RandomForestClassifier(),\n    'Gradient Boosting': GradientBoostingClassifier(),\n    'Gaussian NB': GaussianNB()\n}\n#Define a empty dictionary to store results \nresults = {}\n\nfor model_name, model in models.items():\n    model.fit(xtrain, ytrain)\n    ypred = model.predict(xtest)\n\n    accuracy = accuracy_score(ytest, ypred)\n    f1 = f1_score(ytest, ypred)  # Rename this variable to something else (e.g., f1_score_value)\n    recall = recall_score(ytest, ypred)\n    precision = precision_score(ytest, ypred)\n    roc_auc = roc_auc_score(ytest, ypred)\n\n    results[model_name] = {\n        'Accuracy': accuracy,\n        'f1_score': f1,  # Corrected variable name\n        'Recall': recall,\n        'Precision': precision,\n        'roc_auc_score': roc_auc\n    }\n\n#Print the results   \nfor model_name,metrics in results.items():\n    print(f\"Metrics for {model_name}:\")\n    for metric_name,value in metrics.items():\n        print(f\"{metric_name}:{value}\")\n    print()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"From the above models, the highest accuracy we achieved in Logistic Regression and GauusianNB , but as the data is imbalanced so accuracy won't be the criteria for performance of model, rather we will choose f1 score , so the model which has highest f1 score is Gradient Boosting Model with f1_score of 0.37241379310344824","metadata":{}},{"cell_type":"markdown","source":"### ROC_AUC CURVE","metadata":{}},{"cell_type":"code","source":"from sklearn.metrics import roc_curve, roc_auc_score\n\ngbc=GradientBoostingClassifier()\nmodel=gbc.fit(xtrain,ytrain)\nypred=model.predict(xtest)\n\nfpr,tpr,thresholds=roc_curve(ytest,ypred)\nroc_auc=roc_auc_score(ytest,ypred)\n\nplt.figure(figsize=(17,8))\nplt.plot(fpr, tpr, label='ROC curve (AUC = {:.2f})'.format(roc_auc))\nplt.plot([0, 1], [0, 1], 'k--', label='Random')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate',fontsize=17)\nplt.ylabel('True Positive Rate',fontsize=17)\nplt.title('Receiver Operating Characteristic (ROC) Curve',fontsize=25)\nplt.legend(loc='lower right',fontsize=14)\nplt.show()\n\n\n\n\n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}